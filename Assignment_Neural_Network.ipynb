{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_Neural_Network.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aniketsh1996/Assignment_16/blob/main/Assignment_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSV1PfDiIM_M"
      },
      "source": [
        "# **Forestfires**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nssQk6ByDu0Y",
        "outputId": "a00d9892-a1b1-4a54-b257-6d75dfe2671e"
      },
      "source": [
        "!pip install keras\n",
        "!pip install tensorflow"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.21.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.41.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (12.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xae4rX2YDuyu"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfqhqqUVDuwY"
      },
      "source": [
        "df=pd.read_csv('forestfires.csv')"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "d-8omqnWDuvx",
        "outputId": "eed5bcfb-9474-48d7-9515-670662f2ccc6"
      },
      "source": [
        "df"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>area</th>\n",
              "      <th>dayfri</th>\n",
              "      <th>daymon</th>\n",
              "      <th>daysat</th>\n",
              "      <th>daysun</th>\n",
              "      <th>daythu</th>\n",
              "      <th>daytue</th>\n",
              "      <th>daywed</th>\n",
              "      <th>monthapr</th>\n",
              "      <th>monthaug</th>\n",
              "      <th>monthdec</th>\n",
              "      <th>monthfeb</th>\n",
              "      <th>monthjan</th>\n",
              "      <th>monthjul</th>\n",
              "      <th>monthjun</th>\n",
              "      <th>monthmar</th>\n",
              "      <th>monthmay</th>\n",
              "      <th>monthnov</th>\n",
              "      <th>monthoct</th>\n",
              "      <th>monthsep</th>\n",
              "      <th>size_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mar</td>\n",
              "      <td>fri</td>\n",
              "      <td>86.2</td>\n",
              "      <td>26.2</td>\n",
              "      <td>94.3</td>\n",
              "      <td>5.1</td>\n",
              "      <td>8.2</td>\n",
              "      <td>51</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>oct</td>\n",
              "      <td>tue</td>\n",
              "      <td>90.6</td>\n",
              "      <td>35.4</td>\n",
              "      <td>669.1</td>\n",
              "      <td>6.7</td>\n",
              "      <td>18.0</td>\n",
              "      <td>33</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>oct</td>\n",
              "      <td>sat</td>\n",
              "      <td>90.6</td>\n",
              "      <td>43.7</td>\n",
              "      <td>686.9</td>\n",
              "      <td>6.7</td>\n",
              "      <td>14.6</td>\n",
              "      <td>33</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mar</td>\n",
              "      <td>fri</td>\n",
              "      <td>91.7</td>\n",
              "      <td>33.3</td>\n",
              "      <td>77.5</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.3</td>\n",
              "      <td>97</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mar</td>\n",
              "      <td>sun</td>\n",
              "      <td>89.3</td>\n",
              "      <td>51.3</td>\n",
              "      <td>102.2</td>\n",
              "      <td>9.6</td>\n",
              "      <td>11.4</td>\n",
              "      <td>99</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>aug</td>\n",
              "      <td>sun</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>27.8</td>\n",
              "      <td>32</td>\n",
              "      <td>2.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.44</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>aug</td>\n",
              "      <td>sun</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.9</td>\n",
              "      <td>71</td>\n",
              "      <td>5.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54.29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>aug</td>\n",
              "      <td>sun</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.2</td>\n",
              "      <td>70</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>aug</td>\n",
              "      <td>sat</td>\n",
              "      <td>94.4</td>\n",
              "      <td>146.0</td>\n",
              "      <td>614.7</td>\n",
              "      <td>11.3</td>\n",
              "      <td>25.6</td>\n",
              "      <td>42</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>nov</td>\n",
              "      <td>tue</td>\n",
              "      <td>79.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>106.7</td>\n",
              "      <td>1.1</td>\n",
              "      <td>11.8</td>\n",
              "      <td>31</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>517 rows Ã— 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    month  day  FFMC    DMC  ...  monthnov  monthoct  monthsep  size_category\n",
              "0     mar  fri  86.2   26.2  ...         0         0         0          small\n",
              "1     oct  tue  90.6   35.4  ...         0         1         0          small\n",
              "2     oct  sat  90.6   43.7  ...         0         1         0          small\n",
              "3     mar  fri  91.7   33.3  ...         0         0         0          small\n",
              "4     mar  sun  89.3   51.3  ...         0         0         0          small\n",
              "..    ...  ...   ...    ...  ...       ...       ...       ...            ...\n",
              "512   aug  sun  81.6   56.7  ...         0         0         0          large\n",
              "513   aug  sun  81.6   56.7  ...         0         0         0          large\n",
              "514   aug  sun  81.6   56.7  ...         0         0         0          large\n",
              "515   aug  sat  94.4  146.0  ...         0         0         0          small\n",
              "516   nov  tue  79.5    3.0  ...         1         0         0          small\n",
              "\n",
              "[517 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B_ARfnCDus-"
      },
      "source": [
        "df1=df.drop(['month','day'],axis=1)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qVinUPoDupl"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_EJ0fv_Duoo"
      },
      "source": [
        "lb=LabelEncoder()"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aABhtXeEDulw"
      },
      "source": [
        "df1['size_category']=lb.fit_transform(df1['size_category'])"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwL6lbCyDulB",
        "outputId": "5a076798-bf9c-4a3a-9654-aacbf18636fa"
      },
      "source": [
        "df2=df1.values\n",
        "df2.shape"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(517, 29)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cl-Q8qKjDuhX",
        "outputId": "0f0fc61b-f103-4920-9afb-e8b8cba029e5"
      },
      "source": [
        "x=df2[:,0:28]\n",
        "y=df2[:,-1]\n",
        "x.shape"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(517, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeCqL2M6DueY"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBMi9gweDudu"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=28, activation='relu'))\n",
        "model.add(Dense(28, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIGNb4VoDuah"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYRA18P0DuZu",
        "outputId": "405522cf-3516-40a4-e5f7-a242226fa892"
      },
      "source": [
        "model.fit(x, y, validation_split=0.33,epochs=100, batch_size=5)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "70/70 [==============================] - 1s 4ms/step - loss: 3.2818 - accuracy: 0.7139 - val_loss: 0.7068 - val_accuracy: 0.6842\n",
            "Epoch 2/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.5757 - accuracy: 0.7746 - val_loss: 0.6882 - val_accuracy: 0.7135\n",
            "Epoch 3/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.7861 - val_loss: 0.6113 - val_accuracy: 0.7193\n",
            "Epoch 4/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.8266 - val_loss: 0.5806 - val_accuracy: 0.7076\n",
            "Epoch 5/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8410 - val_loss: 0.5886 - val_accuracy: 0.6491\n",
            "Epoch 6/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8526 - val_loss: 0.6243 - val_accuracy: 0.7485\n",
            "Epoch 7/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.3399 - accuracy: 0.8671 - val_loss: 0.5378 - val_accuracy: 0.7953\n",
            "Epoch 8/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.2920 - accuracy: 0.8757 - val_loss: 0.6192 - val_accuracy: 0.6842\n",
            "Epoch 9/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.2879 - accuracy: 0.8786 - val_loss: 0.5166 - val_accuracy: 0.8070\n",
            "Epoch 10/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.2517 - accuracy: 0.9191 - val_loss: 0.4920 - val_accuracy: 0.7544\n",
            "Epoch 11/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.1955 - accuracy: 0.9277 - val_loss: 0.4144 - val_accuracy: 0.8421\n",
            "Epoch 12/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.1849 - accuracy: 0.9306 - val_loss: 0.5396 - val_accuracy: 0.7135\n",
            "Epoch 13/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.1852 - accuracy: 0.9364 - val_loss: 0.4018 - val_accuracy: 0.8304\n",
            "Epoch 14/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.1490 - accuracy: 0.9451 - val_loss: 0.3828 - val_accuracy: 0.8538\n",
            "Epoch 15/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.1301 - accuracy: 0.9538 - val_loss: 0.3871 - val_accuracy: 0.8304\n",
            "Epoch 16/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.1454 - accuracy: 0.9422 - val_loss: 0.3466 - val_accuracy: 0.8655\n",
            "Epoch 17/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.1234 - accuracy: 0.9595 - val_loss: 0.6181 - val_accuracy: 0.7193\n",
            "Epoch 18/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.1211 - accuracy: 0.9538 - val_loss: 0.3443 - val_accuracy: 0.8713\n",
            "Epoch 19/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0919 - accuracy: 0.9682 - val_loss: 0.3368 - val_accuracy: 0.8889\n",
            "Epoch 20/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.1153 - accuracy: 0.9595 - val_loss: 0.2758 - val_accuracy: 0.8830\n",
            "Epoch 21/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0804 - accuracy: 0.9769 - val_loss: 0.3206 - val_accuracy: 0.8713\n",
            "Epoch 22/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.9855 - val_loss: 0.2773 - val_accuracy: 0.9123\n",
            "Epoch 23/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0809 - accuracy: 0.9711 - val_loss: 0.2921 - val_accuracy: 0.8830\n",
            "Epoch 24/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0615 - accuracy: 0.9827 - val_loss: 0.3815 - val_accuracy: 0.9006\n",
            "Epoch 25/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.9769 - val_loss: 0.2594 - val_accuracy: 0.9123\n",
            "Epoch 26/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0495 - accuracy: 0.9798 - val_loss: 0.2388 - val_accuracy: 0.9181\n",
            "Epoch 27/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.9711 - val_loss: 0.3496 - val_accuracy: 0.8538\n",
            "Epoch 28/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0484 - accuracy: 0.9855 - val_loss: 0.2647 - val_accuracy: 0.9181\n",
            "Epoch 29/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0436 - accuracy: 0.9798 - val_loss: 0.2653 - val_accuracy: 0.9064\n",
            "Epoch 30/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0415 - accuracy: 0.9884 - val_loss: 0.2089 - val_accuracy: 0.9415\n",
            "Epoch 31/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0477 - accuracy: 0.9769 - val_loss: 0.4061 - val_accuracy: 0.8830\n",
            "Epoch 32/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0515 - accuracy: 0.9740 - val_loss: 0.2815 - val_accuracy: 0.9006\n",
            "Epoch 33/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 0.9769 - val_loss: 0.2433 - val_accuracy: 0.9181\n",
            "Epoch 34/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0851 - accuracy: 0.9711 - val_loss: 0.2219 - val_accuracy: 0.9474\n",
            "Epoch 35/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.9798 - val_loss: 0.2109 - val_accuracy: 0.9474\n",
            "Epoch 36/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 0.9827 - val_loss: 0.2034 - val_accuracy: 0.9357\n",
            "Epoch 37/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.9855 - val_loss: 0.2128 - val_accuracy: 0.9415\n",
            "Epoch 38/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0362 - accuracy: 0.9855 - val_loss: 0.2012 - val_accuracy: 0.9357\n",
            "Epoch 39/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.1037 - accuracy: 0.9711 - val_loss: 0.5059 - val_accuracy: 0.8129\n",
            "Epoch 40/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0386 - accuracy: 0.9798 - val_loss: 0.2785 - val_accuracy: 0.9298\n",
            "Epoch 41/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 0.9913 - val_loss: 0.3216 - val_accuracy: 0.8947\n",
            "Epoch 42/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0821 - accuracy: 0.9653 - val_loss: 0.2547 - val_accuracy: 0.9123\n",
            "Epoch 43/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0588 - accuracy: 0.9740 - val_loss: 0.2391 - val_accuracy: 0.9474\n",
            "Epoch 44/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.9740 - val_loss: 0.2636 - val_accuracy: 0.9064\n",
            "Epoch 45/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0421 - accuracy: 0.9942 - val_loss: 0.2211 - val_accuracy: 0.9298\n",
            "Epoch 46/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0362 - accuracy: 0.9884 - val_loss: 0.2531 - val_accuracy: 0.9415\n",
            "Epoch 47/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 0.9884 - val_loss: 0.2252 - val_accuracy: 0.9474\n",
            "Epoch 48/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 0.9913 - val_loss: 0.2124 - val_accuracy: 0.9298\n",
            "Epoch 49/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0262 - accuracy: 0.9884 - val_loss: 0.2009 - val_accuracy: 0.9532\n",
            "Epoch 50/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0318 - accuracy: 0.9913 - val_loss: 0.2364 - val_accuracy: 0.9006\n",
            "Epoch 51/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 0.9913 - val_loss: 0.1847 - val_accuracy: 0.9532\n",
            "Epoch 52/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 0.9855 - val_loss: 0.1933 - val_accuracy: 0.9474\n",
            "Epoch 53/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0315 - accuracy: 0.9913 - val_loss: 0.1936 - val_accuracy: 0.9532\n",
            "Epoch 54/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 0.9913 - val_loss: 0.2267 - val_accuracy: 0.9415\n",
            "Epoch 55/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0226 - accuracy: 0.9913 - val_loss: 0.2129 - val_accuracy: 0.9415\n",
            "Epoch 56/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0431 - accuracy: 0.9884 - val_loss: 0.2973 - val_accuracy: 0.9240\n",
            "Epoch 57/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 0.9855 - val_loss: 0.1863 - val_accuracy: 0.9591\n",
            "Epoch 58/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.9855 - val_loss: 0.3070 - val_accuracy: 0.9064\n",
            "Epoch 59/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.1391 - accuracy: 0.9595 - val_loss: 0.2211 - val_accuracy: 0.9357\n",
            "Epoch 60/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 0.9942 - val_loss: 0.2373 - val_accuracy: 0.9123\n",
            "Epoch 61/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 0.9855 - val_loss: 0.2235 - val_accuracy: 0.9240\n",
            "Epoch 62/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 0.9913 - val_loss: 0.2852 - val_accuracy: 0.9123\n",
            "Epoch 63/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 0.1854 - val_accuracy: 0.9474\n",
            "Epoch 64/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0436 - accuracy: 0.9855 - val_loss: 0.1741 - val_accuracy: 0.9474\n",
            "Epoch 65/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 0.9884 - val_loss: 0.1870 - val_accuracy: 0.9474\n",
            "Epoch 66/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 0.2945 - val_accuracy: 0.9181\n",
            "Epoch 67/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0504 - accuracy: 0.9855 - val_loss: 0.1825 - val_accuracy: 0.9415\n",
            "Epoch 68/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0333 - accuracy: 0.9913 - val_loss: 0.1897 - val_accuracy: 0.9415\n",
            "Epoch 69/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 0.9884 - val_loss: 0.1896 - val_accuracy: 0.9298\n",
            "Epoch 70/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0750 - accuracy: 0.9711 - val_loss: 0.2187 - val_accuracy: 0.9474\n",
            "Epoch 71/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 0.9884 - val_loss: 0.1691 - val_accuracy: 0.9474\n",
            "Epoch 72/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0216 - accuracy: 0.9913 - val_loss: 0.2181 - val_accuracy: 0.9240\n",
            "Epoch 73/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 0.9913 - val_loss: 0.2403 - val_accuracy: 0.9474\n",
            "Epoch 74/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0221 - accuracy: 0.9884 - val_loss: 0.1694 - val_accuracy: 0.9474\n",
            "Epoch 75/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0188 - accuracy: 0.9942 - val_loss: 0.2169 - val_accuracy: 0.9357\n",
            "Epoch 76/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0335 - accuracy: 0.9884 - val_loss: 0.2049 - val_accuracy: 0.9532\n",
            "Epoch 77/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0202 - accuracy: 0.9913 - val_loss: 0.1767 - val_accuracy: 0.9474\n",
            "Epoch 78/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 0.9971 - val_loss: 0.2304 - val_accuracy: 0.9474\n",
            "Epoch 79/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0436 - accuracy: 0.9827 - val_loss: 0.1641 - val_accuracy: 0.9532\n",
            "Epoch 80/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 0.9942 - val_loss: 0.3335 - val_accuracy: 0.9006\n",
            "Epoch 81/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 0.9913 - val_loss: 0.1789 - val_accuracy: 0.9591\n",
            "Epoch 82/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0183 - accuracy: 0.9913 - val_loss: 0.1912 - val_accuracy: 0.9298\n",
            "Epoch 83/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.9884 - val_loss: 0.2825 - val_accuracy: 0.9064\n",
            "Epoch 84/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 0.9942 - val_loss: 0.2090 - val_accuracy: 0.9532\n",
            "Epoch 85/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 0.9884 - val_loss: 0.2646 - val_accuracy: 0.8889\n",
            "Epoch 86/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.2576 - val_accuracy: 0.9357\n",
            "Epoch 87/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 0.9798 - val_loss: 0.2595 - val_accuracy: 0.9415\n",
            "Epoch 88/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0383 - accuracy: 0.9798 - val_loss: 0.2181 - val_accuracy: 0.9298\n",
            "Epoch 89/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 0.9884 - val_loss: 0.2458 - val_accuracy: 0.9181\n",
            "Epoch 90/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 0.9913 - val_loss: 0.4300 - val_accuracy: 0.8947\n",
            "Epoch 91/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0434 - accuracy: 0.9855 - val_loss: 0.1768 - val_accuracy: 0.9357\n",
            "Epoch 92/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.9798 - val_loss: 0.1715 - val_accuracy: 0.9240\n",
            "Epoch 93/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.9855 - val_loss: 0.1559 - val_accuracy: 0.9240\n",
            "Epoch 94/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0453 - accuracy: 0.9855 - val_loss: 0.1679 - val_accuracy: 0.9532\n",
            "Epoch 95/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 0.1661 - val_accuracy: 0.9532\n",
            "Epoch 96/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0120 - accuracy: 0.9971 - val_loss: 0.1621 - val_accuracy: 0.9649\n",
            "Epoch 97/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 0.9855 - val_loss: 0.4889 - val_accuracy: 0.8889\n",
            "Epoch 98/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0736 - accuracy: 0.9711 - val_loss: 0.1883 - val_accuracy: 0.9298\n",
            "Epoch 99/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0858 - accuracy: 0.9711 - val_loss: 0.4855 - val_accuracy: 0.7778\n",
            "Epoch 100/100\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0291 - accuracy: 0.9913 - val_loss: 0.1778 - val_accuracy: 0.9415\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7e84218a10>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obIrKhbzEqgG",
        "outputId": "e96123be-00d2-475a-b5f7-474a43a7369f"
      },
      "source": [
        "scores=model.evaluate(x,y)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17/17 [==============================] - 0s 1ms/step - loss: 0.0761 - accuracy: 0.9749\n",
            "accuracy: 97.49%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sR7V66vmFL19"
      },
      "source": [
        "# **Gas Turbine**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1D_cYc4EqaW"
      },
      "source": [
        "df=pd.read_csv(\"gas_turbines.csv\")"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "u5LzyTWkEqZd",
        "outputId": "c5d4344d-c499-4ca7-d929-cc117bfdce44"
      },
      "source": [
        "df"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AT</th>\n",
              "      <th>AP</th>\n",
              "      <th>AH</th>\n",
              "      <th>AFDP</th>\n",
              "      <th>GTEP</th>\n",
              "      <th>TIT</th>\n",
              "      <th>TAT</th>\n",
              "      <th>TEY</th>\n",
              "      <th>CDP</th>\n",
              "      <th>CO</th>\n",
              "      <th>NOX</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.8594</td>\n",
              "      <td>1007.9</td>\n",
              "      <td>96.799</td>\n",
              "      <td>3.5000</td>\n",
              "      <td>19.663</td>\n",
              "      <td>1059.2</td>\n",
              "      <td>550.00</td>\n",
              "      <td>114.70</td>\n",
              "      <td>10.605</td>\n",
              "      <td>3.1547</td>\n",
              "      <td>82.722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.7850</td>\n",
              "      <td>1008.4</td>\n",
              "      <td>97.118</td>\n",
              "      <td>3.4998</td>\n",
              "      <td>19.728</td>\n",
              "      <td>1059.3</td>\n",
              "      <td>550.00</td>\n",
              "      <td>114.72</td>\n",
              "      <td>10.598</td>\n",
              "      <td>3.2363</td>\n",
              "      <td>82.776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.8977</td>\n",
              "      <td>1008.8</td>\n",
              "      <td>95.939</td>\n",
              "      <td>3.4824</td>\n",
              "      <td>19.779</td>\n",
              "      <td>1059.4</td>\n",
              "      <td>549.87</td>\n",
              "      <td>114.71</td>\n",
              "      <td>10.601</td>\n",
              "      <td>3.2012</td>\n",
              "      <td>82.468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.0569</td>\n",
              "      <td>1009.2</td>\n",
              "      <td>95.249</td>\n",
              "      <td>3.4805</td>\n",
              "      <td>19.792</td>\n",
              "      <td>1059.6</td>\n",
              "      <td>549.99</td>\n",
              "      <td>114.72</td>\n",
              "      <td>10.606</td>\n",
              "      <td>3.1923</td>\n",
              "      <td>82.670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.3978</td>\n",
              "      <td>1009.7</td>\n",
              "      <td>95.150</td>\n",
              "      <td>3.4976</td>\n",
              "      <td>19.765</td>\n",
              "      <td>1059.7</td>\n",
              "      <td>549.98</td>\n",
              "      <td>114.72</td>\n",
              "      <td>10.612</td>\n",
              "      <td>3.2484</td>\n",
              "      <td>82.311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15034</th>\n",
              "      <td>9.0301</td>\n",
              "      <td>1005.6</td>\n",
              "      <td>98.460</td>\n",
              "      <td>3.5421</td>\n",
              "      <td>19.164</td>\n",
              "      <td>1049.7</td>\n",
              "      <td>546.21</td>\n",
              "      <td>111.61</td>\n",
              "      <td>10.400</td>\n",
              "      <td>4.5186</td>\n",
              "      <td>79.559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15035</th>\n",
              "      <td>7.8879</td>\n",
              "      <td>1005.9</td>\n",
              "      <td>99.093</td>\n",
              "      <td>3.5059</td>\n",
              "      <td>19.414</td>\n",
              "      <td>1046.3</td>\n",
              "      <td>543.22</td>\n",
              "      <td>111.78</td>\n",
              "      <td>10.433</td>\n",
              "      <td>4.8470</td>\n",
              "      <td>79.917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15036</th>\n",
              "      <td>7.2647</td>\n",
              "      <td>1006.3</td>\n",
              "      <td>99.496</td>\n",
              "      <td>3.4770</td>\n",
              "      <td>19.530</td>\n",
              "      <td>1037.7</td>\n",
              "      <td>537.32</td>\n",
              "      <td>110.19</td>\n",
              "      <td>10.483</td>\n",
              "      <td>7.9632</td>\n",
              "      <td>90.912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15037</th>\n",
              "      <td>7.0060</td>\n",
              "      <td>1006.8</td>\n",
              "      <td>99.008</td>\n",
              "      <td>3.4486</td>\n",
              "      <td>19.377</td>\n",
              "      <td>1043.2</td>\n",
              "      <td>541.24</td>\n",
              "      <td>110.74</td>\n",
              "      <td>10.533</td>\n",
              "      <td>6.2494</td>\n",
              "      <td>93.227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15038</th>\n",
              "      <td>6.9279</td>\n",
              "      <td>1007.2</td>\n",
              "      <td>97.533</td>\n",
              "      <td>3.4275</td>\n",
              "      <td>19.306</td>\n",
              "      <td>1049.9</td>\n",
              "      <td>545.85</td>\n",
              "      <td>111.58</td>\n",
              "      <td>10.583</td>\n",
              "      <td>4.9816</td>\n",
              "      <td>92.498</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15039 rows Ã— 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           AT      AP      AH    AFDP  ...     TEY     CDP      CO     NOX\n",
              "0      6.8594  1007.9  96.799  3.5000  ...  114.70  10.605  3.1547  82.722\n",
              "1      6.7850  1008.4  97.118  3.4998  ...  114.72  10.598  3.2363  82.776\n",
              "2      6.8977  1008.8  95.939  3.4824  ...  114.71  10.601  3.2012  82.468\n",
              "3      7.0569  1009.2  95.249  3.4805  ...  114.72  10.606  3.1923  82.670\n",
              "4      7.3978  1009.7  95.150  3.4976  ...  114.72  10.612  3.2484  82.311\n",
              "...       ...     ...     ...     ...  ...     ...     ...     ...     ...\n",
              "15034  9.0301  1005.6  98.460  3.5421  ...  111.61  10.400  4.5186  79.559\n",
              "15035  7.8879  1005.9  99.093  3.5059  ...  111.78  10.433  4.8470  79.917\n",
              "15036  7.2647  1006.3  99.496  3.4770  ...  110.19  10.483  7.9632  90.912\n",
              "15037  7.0060  1006.8  99.008  3.4486  ...  110.74  10.533  6.2494  93.227\n",
              "15038  6.9279  1007.2  97.533  3.4275  ...  111.58  10.583  4.9816  92.498\n",
              "\n",
              "[15039 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEzjhAMQFkLL",
        "outputId": "461edcad-6a37-4bb4-a906-07dc75cad72a"
      },
      "source": [
        "df1=df.values\n",
        "df1"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   6.8594, 1007.9   ,   96.799 , ...,   10.605 ,    3.1547,\n",
              "          82.722 ],\n",
              "       [   6.785 , 1008.4   ,   97.118 , ...,   10.598 ,    3.2363,\n",
              "          82.776 ],\n",
              "       [   6.8977, 1008.8   ,   95.939 , ...,   10.601 ,    3.2012,\n",
              "          82.468 ],\n",
              "       ...,\n",
              "       [   7.2647, 1006.3   ,   99.496 , ...,   10.483 ,    7.9632,\n",
              "          90.912 ],\n",
              "       [   7.006 , 1006.8   ,   99.008 , ...,   10.533 ,    6.2494,\n",
              "          93.227 ],\n",
              "       [   6.9279, 1007.2   ,   97.533 , ...,   10.583 ,    4.9816,\n",
              "          92.498 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkJGVgQhFkKe",
        "outputId": "675106b2-c348-43d9-b859-cd026b16d324"
      },
      "source": [
        "X=df1[:,[0,1,2,3,4,5,6,8,9,10]]\n",
        "Y=df1[:,-4]\n",
        "X"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   6.8594, 1007.9   ,   96.799 , ...,   10.605 ,    3.1547,\n",
              "          82.722 ],\n",
              "       [   6.785 , 1008.4   ,   97.118 , ...,   10.598 ,    3.2363,\n",
              "          82.776 ],\n",
              "       [   6.8977, 1008.8   ,   95.939 , ...,   10.601 ,    3.2012,\n",
              "          82.468 ],\n",
              "       ...,\n",
              "       [   7.2647, 1006.3   ,   99.496 , ...,   10.483 ,    7.9632,\n",
              "          90.912 ],\n",
              "       [   7.006 , 1006.8   ,   99.008 , ...,   10.533 ,    6.2494,\n",
              "          93.227 ],\n",
              "       [   6.9279, 1007.2   ,   97.533 , ...,   10.583 ,    4.9816,\n",
              "          92.498 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqqcddmwFkHF"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2g1qhUIfFkCY"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size=0.25,random_state=101)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GDBJng8Fj9-"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkWZpFkDFj8O",
        "outputId": "31b7b1d3-d382-4bcf-91e0-68782daa2a60"
      },
      "source": [
        "scaler=MinMaxScaler()\n",
        "scaler.fit(x_train)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MinMaxScaler(copy=True, feature_range=(0, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LdpMVNkGC7H",
        "outputId": "99e21c56-2be7-48ea-bbc4-f3ef8985956d"
      },
      "source": [
        "x_train=scaler.transform(x_train)\n",
        "x_test=scaler.transform(x_test)\n",
        "x_test"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35890393, 0.40602285, 0.91801706, ..., 0.34107329, 0.03084967,\n",
              "        0.48475958],\n",
              "       [0.55162803, 0.59086189, 0.72785444, ..., 0.42819611, 0.02833486,\n",
              "        0.43366477],\n",
              "       [0.69430373, 0.53478712, 0.55215014, ..., 0.14847583, 0.15186537,\n",
              "        0.33822331],\n",
              "       ...,\n",
              "       [0.29923532, 0.48494289, 0.94876603, ..., 0.77514199, 0.00101504,\n",
              "        0.41400706],\n",
              "       [0.64399376, 0.35825545, 0.50904718, ..., 0.04705791, 0.10100297,\n",
              "        0.36756316],\n",
              "       [0.3486443 , 0.24340602, 0.81637941, ..., 0.34416412, 0.00787964,\n",
              "        0.54170062]])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhekVuokGC5l"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "# add nodes for prediction\n",
        "model.add(Dense(1))"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2bEt6ZGGC2M"
      },
      "source": [
        "model.compile(optimizer='rmsprop',loss='mse')"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d6DG8b5GCxl",
        "outputId": "bcffb684-01ce-45c4-fcc8-f3c5704f89ca"
      },
      "source": [
        "# Fit the model\n",
        "model.fit(x_train, y_train, epochs=250)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "353/353 [==============================] - 1s 982us/step - loss: 15722.5898\n",
            "Epoch 2/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 3586.2864\n",
            "Epoch 3/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 34.3342\n",
            "Epoch 4/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 23.0907\n",
            "Epoch 5/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 19.7388\n",
            "Epoch 6/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 17.0087\n",
            "Epoch 7/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 14.7156\n",
            "Epoch 8/250\n",
            "353/353 [==============================] - 0s 990us/step - loss: 10.8337\n",
            "Epoch 9/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 8.1163\n",
            "Epoch 10/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 6.2471\n",
            "Epoch 11/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 4.9256\n",
            "Epoch 12/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 4.0369\n",
            "Epoch 13/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 3.4527\n",
            "Epoch 14/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 3.0852\n",
            "Epoch 15/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 2.8173\n",
            "Epoch 16/250\n",
            "353/353 [==============================] - 0s 967us/step - loss: 2.6295\n",
            "Epoch 17/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 2.4608\n",
            "Epoch 18/250\n",
            "353/353 [==============================] - 0s 960us/step - loss: 2.3295\n",
            "Epoch 19/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 2.2216\n",
            "Epoch 20/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 2.1024\n",
            "Epoch 21/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 2.0092\n",
            "Epoch 22/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 1.8947\n",
            "Epoch 23/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 1.8232\n",
            "Epoch 24/250\n",
            "353/353 [==============================] - 0s 964us/step - loss: 1.7354\n",
            "Epoch 25/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 1.6540\n",
            "Epoch 26/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 1.5733\n",
            "Epoch 27/250\n",
            "353/353 [==============================] - 0s 980us/step - loss: 1.5151\n",
            "Epoch 28/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 1.4483\n",
            "Epoch 29/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 1.3898\n",
            "Epoch 30/250\n",
            "353/353 [==============================] - 0s 994us/step - loss: 1.3400\n",
            "Epoch 31/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 1.2783\n",
            "Epoch 32/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 1.2360\n",
            "Epoch 33/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 1.2038\n",
            "Epoch 34/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 1.1507\n",
            "Epoch 35/250\n",
            "353/353 [==============================] - 0s 988us/step - loss: 1.1198\n",
            "Epoch 36/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 1.0735\n",
            "Epoch 37/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 1.0385\n",
            "Epoch 38/250\n",
            "353/353 [==============================] - 0s 998us/step - loss: 1.0028\n",
            "Epoch 39/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.9880\n",
            "Epoch 40/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.9596\n",
            "Epoch 41/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.9243\n",
            "Epoch 42/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.9053\n",
            "Epoch 43/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.8965\n",
            "Epoch 44/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.8800\n",
            "Epoch 45/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.8807\n",
            "Epoch 46/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.8607\n",
            "Epoch 47/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.8536\n",
            "Epoch 48/250\n",
            "353/353 [==============================] - 0s 994us/step - loss: 0.8520\n",
            "Epoch 49/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.8391\n",
            "Epoch 50/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.8485\n",
            "Epoch 51/250\n",
            "353/353 [==============================] - 0s 986us/step - loss: 0.8397\n",
            "Epoch 52/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.8382\n",
            "Epoch 53/250\n",
            "353/353 [==============================] - 0s 986us/step - loss: 0.8364\n",
            "Epoch 54/250\n",
            "353/353 [==============================] - 0s 992us/step - loss: 0.8296\n",
            "Epoch 55/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.8347\n",
            "Epoch 56/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.8367\n",
            "Epoch 57/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.8409\n",
            "Epoch 58/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.8279\n",
            "Epoch 59/250\n",
            "353/353 [==============================] - 0s 988us/step - loss: 0.8249\n",
            "Epoch 60/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.8397\n",
            "Epoch 61/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.8325\n",
            "Epoch 62/250\n",
            "353/353 [==============================] - 0s 980us/step - loss: 0.8346\n",
            "Epoch 63/250\n",
            "353/353 [==============================] - 0s 995us/step - loss: 0.8164\n",
            "Epoch 64/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.8298\n",
            "Epoch 65/250\n",
            "353/353 [==============================] - 0s 991us/step - loss: 0.8178\n",
            "Epoch 66/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.8278\n",
            "Epoch 67/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.8191\n",
            "Epoch 68/250\n",
            "353/353 [==============================] - 0s 994us/step - loss: 0.8132\n",
            "Epoch 69/250\n",
            "353/353 [==============================] - 0s 984us/step - loss: 0.8250\n",
            "Epoch 70/250\n",
            "353/353 [==============================] - 0s 970us/step - loss: 0.8345\n",
            "Epoch 71/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.8189\n",
            "Epoch 72/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.8190\n",
            "Epoch 73/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.8088\n",
            "Epoch 74/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.8114\n",
            "Epoch 75/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.8095\n",
            "Epoch 76/250\n",
            "353/353 [==============================] - 0s 989us/step - loss: 0.8092\n",
            "Epoch 77/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.8122\n",
            "Epoch 78/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.8128\n",
            "Epoch 79/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.8110\n",
            "Epoch 80/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.8076\n",
            "Epoch 81/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.8168\n",
            "Epoch 82/250\n",
            "353/353 [==============================] - 0s 996us/step - loss: 0.8122\n",
            "Epoch 83/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.8096\n",
            "Epoch 84/250\n",
            "353/353 [==============================] - 0s 987us/step - loss: 0.7989\n",
            "Epoch 85/250\n",
            "353/353 [==============================] - 0s 967us/step - loss: 0.8054\n",
            "Epoch 86/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.8118\n",
            "Epoch 87/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.8078\n",
            "Epoch 88/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7977\n",
            "Epoch 89/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.8014\n",
            "Epoch 90/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7970\n",
            "Epoch 91/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7934\n",
            "Epoch 92/250\n",
            "353/353 [==============================] - 0s 990us/step - loss: 0.8051\n",
            "Epoch 93/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7998\n",
            "Epoch 94/250\n",
            "353/353 [==============================] - 0s 989us/step - loss: 0.7941\n",
            "Epoch 95/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7898\n",
            "Epoch 96/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7881\n",
            "Epoch 97/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7924\n",
            "Epoch 98/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7951\n",
            "Epoch 99/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7924\n",
            "Epoch 100/250\n",
            "353/353 [==============================] - 0s 983us/step - loss: 0.7868\n",
            "Epoch 101/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7762\n",
            "Epoch 102/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7843\n",
            "Epoch 103/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7939\n",
            "Epoch 104/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7934\n",
            "Epoch 105/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7796\n",
            "Epoch 106/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7942\n",
            "Epoch 107/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7799\n",
            "Epoch 108/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7909\n",
            "Epoch 109/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7905\n",
            "Epoch 110/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7855\n",
            "Epoch 111/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7809\n",
            "Epoch 112/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7781\n",
            "Epoch 113/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7772\n",
            "Epoch 114/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7789\n",
            "Epoch 115/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7734\n",
            "Epoch 116/250\n",
            "353/353 [==============================] - 0s 992us/step - loss: 0.7729\n",
            "Epoch 117/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7785\n",
            "Epoch 118/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7742\n",
            "Epoch 119/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7694\n",
            "Epoch 120/250\n",
            "353/353 [==============================] - 0s 999us/step - loss: 0.7721\n",
            "Epoch 121/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7703\n",
            "Epoch 122/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7740\n",
            "Epoch 123/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7681\n",
            "Epoch 124/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7613\n",
            "Epoch 125/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7787\n",
            "Epoch 126/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7756\n",
            "Epoch 127/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7629\n",
            "Epoch 128/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7721\n",
            "Epoch 129/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7796\n",
            "Epoch 130/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7770\n",
            "Epoch 131/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7630\n",
            "Epoch 132/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7565\n",
            "Epoch 133/250\n",
            "353/353 [==============================] - 0s 1000us/step - loss: 0.7560\n",
            "Epoch 134/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7584\n",
            "Epoch 135/250\n",
            "353/353 [==============================] - 0s 982us/step - loss: 0.7578\n",
            "Epoch 136/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7623\n",
            "Epoch 137/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7588\n",
            "Epoch 138/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7675\n",
            "Epoch 139/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7613\n",
            "Epoch 140/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7498\n",
            "Epoch 141/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7538\n",
            "Epoch 142/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7524\n",
            "Epoch 143/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7617\n",
            "Epoch 144/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7461\n",
            "Epoch 145/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7540\n",
            "Epoch 146/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7521\n",
            "Epoch 147/250\n",
            "353/353 [==============================] - 0s 1000us/step - loss: 0.7461\n",
            "Epoch 148/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7633\n",
            "Epoch 149/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7433\n",
            "Epoch 150/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7455\n",
            "Epoch 151/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7587\n",
            "Epoch 152/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7547\n",
            "Epoch 153/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7535\n",
            "Epoch 154/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7481\n",
            "Epoch 155/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7465\n",
            "Epoch 156/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7542\n",
            "Epoch 157/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7428\n",
            "Epoch 158/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7425\n",
            "Epoch 159/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7442\n",
            "Epoch 160/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7544\n",
            "Epoch 161/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7447\n",
            "Epoch 162/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7529\n",
            "Epoch 163/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7475\n",
            "Epoch 164/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7459\n",
            "Epoch 165/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7459\n",
            "Epoch 166/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7341\n",
            "Epoch 167/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7424\n",
            "Epoch 168/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7372\n",
            "Epoch 169/250\n",
            "353/353 [==============================] - 0s 993us/step - loss: 0.7397\n",
            "Epoch 170/250\n",
            "353/353 [==============================] - 0s 987us/step - loss: 0.7480\n",
            "Epoch 171/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7410\n",
            "Epoch 172/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7260\n",
            "Epoch 173/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7403\n",
            "Epoch 174/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7363\n",
            "Epoch 175/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7421\n",
            "Epoch 176/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7261\n",
            "Epoch 177/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7333\n",
            "Epoch 178/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7391\n",
            "Epoch 179/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7320\n",
            "Epoch 180/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7420\n",
            "Epoch 181/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7293\n",
            "Epoch 182/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7409\n",
            "Epoch 183/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7305\n",
            "Epoch 184/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7312\n",
            "Epoch 185/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7275\n",
            "Epoch 186/250\n",
            "353/353 [==============================] - 0s 994us/step - loss: 0.7222\n",
            "Epoch 187/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7213\n",
            "Epoch 188/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7279\n",
            "Epoch 189/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7344\n",
            "Epoch 190/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7242\n",
            "Epoch 191/250\n",
            "353/353 [==============================] - 0s 988us/step - loss: 0.7348\n",
            "Epoch 192/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7297\n",
            "Epoch 193/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7357\n",
            "Epoch 194/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7327\n",
            "Epoch 195/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7196\n",
            "Epoch 196/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7318\n",
            "Epoch 197/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7268\n",
            "Epoch 198/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7357\n",
            "Epoch 199/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7260\n",
            "Epoch 200/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7258\n",
            "Epoch 201/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7202\n",
            "Epoch 202/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7287\n",
            "Epoch 203/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7240\n",
            "Epoch 204/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7358\n",
            "Epoch 205/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7194\n",
            "Epoch 206/250\n",
            "353/353 [==============================] - 0s 998us/step - loss: 0.7188\n",
            "Epoch 207/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7230\n",
            "Epoch 208/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7168\n",
            "Epoch 209/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7183\n",
            "Epoch 210/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7227\n",
            "Epoch 211/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7226\n",
            "Epoch 212/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7202\n",
            "Epoch 213/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7199\n",
            "Epoch 214/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7124\n",
            "Epoch 215/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7165\n",
            "Epoch 216/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7273\n",
            "Epoch 217/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7236\n",
            "Epoch 218/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7175\n",
            "Epoch 219/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7149\n",
            "Epoch 220/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7116\n",
            "Epoch 221/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7168\n",
            "Epoch 222/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7126\n",
            "Epoch 223/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7174\n",
            "Epoch 224/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7192\n",
            "Epoch 225/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7192\n",
            "Epoch 226/250\n",
            "353/353 [==============================] - 0s 999us/step - loss: 0.7092\n",
            "Epoch 227/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7162\n",
            "Epoch 228/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7148\n",
            "Epoch 229/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7115\n",
            "Epoch 230/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7136\n",
            "Epoch 231/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7097\n",
            "Epoch 232/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7147\n",
            "Epoch 233/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7116\n",
            "Epoch 234/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.6948\n",
            "Epoch 235/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7167\n",
            "Epoch 236/250\n",
            "353/353 [==============================] - 0s 998us/step - loss: 0.7135\n",
            "Epoch 237/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7064\n",
            "Epoch 238/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7017\n",
            "Epoch 239/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7067\n",
            "Epoch 240/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7141\n",
            "Epoch 241/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7000\n",
            "Epoch 242/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7042\n",
            "Epoch 243/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7090\n",
            "Epoch 244/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7039\n",
            "Epoch 245/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7049\n",
            "Epoch 246/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7125\n",
            "Epoch 247/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7092\n",
            "Epoch 248/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7074\n",
            "Epoch 249/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.7046\n",
            "Epoch 250/250\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.6999\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7e03c10d10>"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "tMEPdFMCGgIU",
        "outputId": "b4cbe706-c82c-4dc6-f209-6067fec1a4b0"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib as plot\n",
        "model_loss = pd.DataFrame(model.history.history)\n",
        "model_loss.plot()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7e03b8db10>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZiW-AxXGgE9"
      },
      "source": [
        "pred = model.predict(x_test)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXMXNQmkGgD3",
        "outputId": "ceae793d-fdb9-425b-e3a9-a48c4e3d2d50"
      },
      "source": [
        "pred"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[131.9494  ],\n",
              "       [133.3162  ],\n",
              "       [110.57254 ],\n",
              "       ...,\n",
              "       [159.9654  ],\n",
              "       [104.052635],\n",
              "       [132.32317 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXtkP1SBGgCc"
      },
      "source": [
        "pred = pred.ravel()"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUJFrRhBGf-8",
        "outputId": "539a59f4-42b6-4b83-c850-74b596db8c6f"
      },
      "source": [
        "test_score = model.evaluate(x_test,y_test,verbose=0)\n",
        "test_score"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7546501755714417"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVBpDxa6Gae6"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error,mean_squared_error"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sz5AnGJGbcD",
        "outputId": "b088bd6e-e93f-412b-a980-4d2ae985a8d6"
      },
      "source": [
        "mean_absolute_error(pred,y_test)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6965096364122757"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_8uq58MGh8i",
        "outputId": "71220018-8e44-40ec-e6ef-6d8b7c53ad68"
      },
      "source": [
        "mean_squared_error(pred,y_test)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7546495434845151"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z89bjx_HILX_"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "4X-3Q_D_ISpd",
        "outputId": "2362c9ad-b7df-4126-d4ee-be7082a3ea5e"
      },
      "source": [
        "plt.scatter(y_test,pred)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f7e03a70c90>"
            ]
          },
          "metadata": {},
          "execution_count": 97
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOVGmtQxIW4C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}